# -*- coding: utf-8 -*-
# @Time    : 2025/9/24 23:01
# @Author  : yeye
# @File    : llm.py
# @Software: PyCharm
# @Desc    :
import requests
from config import LLM_URL, HEADERS

import re
def clean_text(text: str) -> str:
    text = re.sub(r"[\*\[\]]+", "", text)
    text = re.sub(r"\s+", " ", text)
    return text.strip()
def call_llm(user_text, session_history):
    session_history.append({"role": "user", "content": user_text})
    payload = {
        "model": "gpt-oss-120b",
        "stream": False,
        "messages": session_history
    }
    resp = requests.post(LLM_URL, headers=HEADERS, json=payload, timeout=30).json()
    reply = resp["choices"][0]["message"]["content"]
    reply = clean_text(reply)
    session_history.append({"role": "assistant", "content": reply})
    print("ğŸ¤– LLM å›å¤:", reply)
    return reply


def classify_text(text: str, task: str, choices=None, timeout=15):
    """
    ä½¿ç”¨ LLM åšåˆ†ç±»ä»»åŠ¡ï¼šè¿”å›åŸå§‹ LLM æ–‡æœ¬ï¼ˆå»ºè®®è¦æ±‚ JSON æ ¼å¼è¿”å›ï¼‰
    è°ƒç”¨ç¤ºä¾‹ task="æƒ…ç»ªåˆ†ç±»: é€‰é¡¹[positive, neutral, negative, sad]"
    """
    sys_prompt = "ä½ æ˜¯ä¸€ä¸ªç®€çŸ­æ–‡æœ¬çš„åˆ†ç±»å™¨ã€‚è¯·åªç”¨ä¸€å¥è¯æˆ–ä¸€ä¸ªè¯å›ç­”ï¼ˆå°½é‡ç»™å‡ºæ ‡å‡†é€‰é¡¹ï¼‰ï¼Œä¸è¦é•¿ç¯‡è¾“å‡ºã€‚"
    user_prompt = f"ä»»åŠ¡æè¿°: {task}\næ–‡æœ¬: '''{text}'''\nè¯·ç›´æ¥è¾“å‡ºåˆ†ç±»æ ‡ç­¾ã€‚"
    payload = {
        "model": "gpt-oss-120b",
        "stream": False,
        "messages": [
            {"role": "system", "content": sys_prompt},
            {"role": "user", "content": user_prompt}
        ]
    }
    try:
        resp = requests.post(LLM_URL, headers=HEADERS, json=payload, timeout=timeout)
        data = resp.json()
        label = data["choices"][0]["message"]["content"].strip()
        return label
    except Exception as e:
        # è¯·æ±‚å¤±è´¥åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²
        return ""
